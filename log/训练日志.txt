2020.1.15 
测试发现有一些bug，比如范和丘重叠太高，李字和屠字关系太近，所以增加了cnnsize到512 ，layer=4，扩大范围进行训练
2020.1.16
昨天的训练不理想，至少不显著，考虑缩小c256l3来加速，因为训练不完基本无法测试，epoch10结果很不理想，10小时，此外调整古诗学习在前，起名训练在后，起名数据量翻倍测试
2020.1.17
调整到cnn256l3以后效果还可以，分词会平均化，但是训练速度还是比较慢的，公司在跑，应该模型结果今天早上去看
此外，如果想js层面使用，需要使用keras来做训练改善，而不能使用tf本身了，这种存储的改变问题好多，主要是为了兼容tf.js不知道当初怎么想的，以后是不是还并行两个方案
2020.1.17
目前可以转移模型到js状态，但是看文件数量和大小感觉不对，此外，恢复业务的时候，用新的save_model方式感觉没有恢复图，产生的名字并没有序列